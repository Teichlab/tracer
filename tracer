#!/usr/bin/env python

import pdb

############################################################################## 
# TraCeR - a tool to reconstruct TCR sequences from single-cell RNA-seq data #
#                      EDIT tracer.conf BEFORE USE!                          #       
#                                                                            #
# Please see README and LICENCE for details of use and licence conditions.   #
# This software was written by Mike Stubbington (mstubb@ebi.ac.uk) from the  #
# Teichmann Lab, EMBL-EBI (www.teichlab.org). Latest versions are available  #
# for download at www.github.com/teichlab/tracer.                            #
#                                                                            #
#      Copyright (c) 2015 EMBL - European Bioinformatics Institute           # 
############################################################################## 


import matplotlib as mpl
mpl.use('pdf')
import seaborn as sns
from matplotlib import pyplot as plt
import tracer_func as tracer
import ConfigParser
import argparse
import sys
import os
import subprocess
import pipes
import glob
import shutil
import re
from collections import defaultdict, Counter
from time import sleep
import warnings
import pickle
from prettytable import PrettyTable


class Launcher():
    def __init__(self):
        parser = argparse.ArgumentParser(description='TraCeR: reconstruction of TCR sequences from single-cell RNAseq data', usage = ''' tracer <mode> [<args>]
        
        Modes are :
        
        - assemble: assemble TCR sequences from single-cell RNA-sequencing reads
        - summarise: summarise TCR sequences from set of cells, build clonotype networks
        - build_synth_genome: build synthetic genomes and Bowtie2 indices for read extraction
        - build_igblast_index: build index for use with IgBlast
        
        use tracer <mode> -h for specific help
        ''')
        parser.add_argument('mode', metavar="<MODE>", help='tracer mode (assemble, build or summarise)', choices = ['assemble', 'build_synth_genome', 'summarise', 'summarize', 'build_igblast_index'])
        args = parser.parse_args(sys.argv[1:2])
        
        if not hasattr(self, args.mode):
            print 'Unrecognised mode'
            parser.print_help()
            exit(1)
        
        
        
        
        getattr(self, args.mode)()
        
        
        
        
        
        
        
    ##ASSEMBLE
    def assemble(self):
        parser = argparse.ArgumentParser(description = "Reconstruct TCR sequences from RNAseq reads for a single cell")
        parser.add_argument('--ncores', '-p', metavar="<CORES>", help='number of processor cores to use', type=int, default=1)
        parser.add_argument('--config_file', '-c', metavar="<CONFIG_FILE>", help='config file to use [tracer.conf]', default='tracer.conf')
        parser.add_argument('--resume_with_existing_files', '-r', help='look for existing intermediate files and use those instead of starting from scratch', action="store_true")
        parser.add_argument('fastq1', metavar="<FASTQ1>", help='first fastq file')
        parser.add_argument('fastq2', metavar="<FASTQ2>", help='second fastq file')
        parser.add_argument('cell_name', metavar="<CELL_NAME>", help='name of cell for file labels')
        parser.add_argument('output_dir', metavar="<OUTPUT_DIR>", help='directory for output as <output_dir>/<cell_name>')
        args = parser.parse_args(sys.argv[2:])
        
        cell_name = args.cell_name
        fastq1 = args.fastq1
        fastq2 = args.fastq2
        ncores = str(args.ncores)
        
        #Read config file
        config = ConfigParser.ConfigParser()
        config.read(args.config_file)
        
        bowtie2 = config.get('tool_locations', 'bowtie2_path')
        igblast = config.get('tool_locations', 'igblast_path')
        kallisto = config.get('tool_locations', 'kallisto_path')
        trinity = config.get('tool_locations', 'trinity_path')
        
        if config.has_option('trinity_options', 'trinity_grid_conf'):
            trinity_grid_conf = config.get('trinity_options', 'trinity_grid_conf')
        else:
            trinity_grid_conf = False
        
        
        
        synthetic_genome_path = config.get('bowtie2_options', 'synthetic_genome_index_path')
        
        igblast_index_location = config.get('IgBlast_options', 'igblast_index_location')
        #igblast_aux_data = config.get('IgBlast_options', 'igblast_aux_data')
        #organism = config.get('IgBlast_options', 'igblast_organism')
        igblast_seqtype = config.get('IgBlast_options', 'igblast_seqtype')
        imgt_seq_location = config.get('IgBlast_options', 'imgt_seq_location')
        
        
        kallisto_base_transcriptome = config.get('kallisto_options', 'base_transcriptome')
        
        #check that executables from config file can be used
        not_executable = []
        for name, x in {"bowtie2":bowtie2, "igblast":igblast, "kallisto":kallisto, "trinity":trinity}.iteritems():
            if not tracer.is_exe(x):
                not_executable.append((name, x))
        if len(not_executable) > 0:
            print
            print "Could not execute the following required tools. Check your configuration file."
            for t in not_executable:
                print t[0], t[1]
            print
            exit(1)
            
        
        #set-up output directories
        root_output_dir = os.path.abspath(args.output_dir)
        tracer.makeOutputDir(root_output_dir)
        output_dir = root_output_dir + "/" + cell_name
        
        tracer.makeOutputDir(output_dir)
        
        data_dirs = ['aligned_reads','Trinity_output', 'IgBLAST_output', 'unfiltered_TCR_seqs', 'expression_quantification', 'filtered_TCR_seqs']
        for d in data_dirs:
            tracer.makeOutputDir("{}/{}".format(output_dir, d))
        
        locus_names = ["TCRA", "TCRB"]
        
        should_resume = args.resume_with_existing_files
        
        self.bowtie2_alignment(bowtie2, ncores, locus_names, output_dir, cell_name, synthetic_genome_path, fastq1, fastq2, should_resume)
        print
        trinity_JM = config.get('trinity_options', 'max_jellyfish_memory')
        self.assemble_with_trinity(trinity, locus_names, output_dir, cell_name, ncores, trinity_grid_conf, trinity_JM, should_resume)
        print        
        self.run_IgBlast(igblast, locus_names, output_dir, cell_name, igblast_index_location, igblast_seqtype, should_resume)
        print
        
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            cell = tracer.parse_IgBLAST(locus_names, output_dir, cell_name, imgt_seq_location)

        self.quantify_with_kallisto(kallisto, cell, output_dir, cell_name, kallisto_base_transcriptome, fastq1, fastq2, ncores, should_resume)
        
        print
        
        counts = tracer.load_kallisto_counts("{}/expression_quantification/kallisto_output/abundance.tsv".format(output_dir))
        
        for locus, recombinants in cell.all_recombinants.iteritems():
            if recombinants is not None:
                for rec in recombinants:
                    tpm = counts[locus][rec.contig_name]
                    rec.TPM = tpm
        
        self.print_cell_summary(cell, "{output_dir}/unfiltered_TCR_seqs/unfiltered_TCRs.txt".format(output_dir=output_dir))
        pickle.dump(cell, open("{output_dir}/unfiltered_TCR_seqs/{cell_name}.pkl".format(output_dir=output_dir, cell_name=cell.name), 'w'))
        print "##Filtering by read count##"
        cell.filter_recombinants()
        fasta_filename = "{output_dir}/filtered_TCR_seqs/{cell_name}_TCRseqs.fa".format(output_dir=output_dir, cell_name=cell_name)
        fasta_file = open(fasta_filename, 'w')
        fasta_file.write(cell.get_fasta_string())    
        fasta_file.close()
        self.print_cell_summary(cell, "{output_dir}/filtered_TCR_seqs/filtered_TCRs.txt".format(output_dir=output_dir))
        pickle.dump(cell, open("{output_dir}/filtered_TCR_seqs/{cell_name}.pkl".format(output_dir=output_dir, cell_name=cell.name), 'w'))
        
    def bowtie2_alignment(self, bowtie2, ncores, locus_names, output_dir, cell_name, synthetic_genome_path, fastq1, fastq2, should_resume):
        print "##Finding TCR-derived reads##"
        
        if should_resume:
            for locus in locus_names:
                aligned_read_path = "{}/aligned_reads/{}_{}_".format(output_dir, cell_name, locus)
                fastq1_out= "{}1.fastq".format(aligned_read_path)
                fastq2_out= "{}2.fastq".format(aligned_read_path)
                if os.path.isfile(fastq1_out) and os.path.isfile(fastq2_out):
                    print "Resuming with existing TCRA and B reads"
                    return
        
        for locus in locus_names:
            print "##{}##".format(locus)
            sam_file = "{}/aligned_reads/{}_{}.sam".format(output_dir, cell_name, locus)
            aligned_read_path = "{}/aligned_reads/{}_{}_%.fastq".format(output_dir, cell_name, locus)
            command = [bowtie2, '--no-unal', '-p', ncores, '-k', '1', '--np', '0', '--rdg', '1,1', '--rfg', '1,1', '-x', "/".join([synthetic_genome_path, locus]), '-1', fastq1, '-2', fastq2, '--al-conc', aligned_read_path, '-S', sam_file]
            

            subprocess.check_call(command)
        
            
    
    
    
    
    def assemble_with_trinity(self, trinity, locus_names, output_dir, cell_name, ncores, trinity_grid_conf, JM, should_resume):
        print  "##Assembling Trinity Contigs##"
        
        if should_resume:
            trinity_report_successful =  "{}/Trinity_output/successful_trinity_assemblies.txt".format(output_dir)
            trinity_report_unsuccessful = "{}/Trinity_output/unsuccessful_trinity_assemblies.txt".format(output_dir)
            if (os.path.isfile(trinity_report_successful) and os.path.isfile(trinity_report_unsuccessful)) and (os.path.getsize(trinity_report_successful) >0 or os.path.getsize(trinity_report_unsuccessful) >0) :
                print "Resuming with existing Trinity output"
                return
        
        
        command = [trinity]
        if trinity_grid_conf:
            command = command + ['--grid_conf', trinity_grid_conf]
        
        command = command + ['--JM', JM, '--seqType', 'fq', '--CPU', ncores, '--full_cleanup']
        
        for locus in locus_names:
            print "##{}##".format(locus)
            trinity_output = "{}/Trinity_output/{}_{}".format(output_dir, cell_name, locus)
            aligned_read_path = "{}/aligned_reads/{}_{}_".format(output_dir, cell_name, locus)
            file1 = "{}1.fastq".format(aligned_read_path)
            file2 = "{}2.fastq".format(aligned_read_path)
            command = command + ["--left", file1, "--right", file2, "--output", '{}'.format(trinity_output)]
            subprocess.check_call(command)
        
        #clean up unsuccessful assemblies
        sleep(10) #this gives the cluster filesystem time to catch up and stops weird things happening
        successful_files = glob.glob("{}/Trinity_output/*.fasta".format(output_dir))
        unsuccessful_directories = os.walk("{}/Trinity_output".format(output_dir)).next()[1]
        for directory in unsuccessful_directories:
            shutil.rmtree(directory)
        successful_file_summary = "{}/Trinity_output/successful_trinity_assemblies.txt".format(output_dir)
        unsuccessful_file_summary = "{}/Trinity_output/unsuccessful_trinity_assemblies.txt".format(output_dir)
    
        successful_files = tracer.clean_file_list(successful_files)
        unsuccessful_directories = tracer.clean_file_list(unsuccessful_directories)

    
        success_out = open(successful_file_summary, "w")
        fail_out = open(unsuccessful_file_summary, "w")
    
        successful = defaultdict(list)
        unsuccessful = defaultdict(list)
    
        successful_ordered_files = set()
        unsuccessful_ordered_files = set()
    
        for filename in successful_files:
            #success_out.write("{}\n".format(filename))
            parsed_name = tracer.get_filename_and_locus(filename)
            successful[parsed_name[0]].append(parsed_name[1])
            successful_ordered_files.add(parsed_name[0])
        successful_ordered_files = sorted(list(successful_ordered_files))
        
    
        for filename in unsuccessful_directories:
            #fail_out.write("{}\n".format(filename))
            parsed_name = tracer.get_filename_and_locus(filename)
            unsuccessful[parsed_name[0]].append(parsed_name[1])
            unsuccessful_ordered_files.add(parsed_name[0])
        unsuccessful_ordered_files = sorted(list(unsuccessful_ordered_files))
        
        successful = tracer.sort_locus_names(successful)
        unsuccessful = tracer.sort_locus_names(unsuccessful)
    
        for file in successful_ordered_files:
            success_out.write("{}\t{}\n".format(file, successful[file]))
    
        for file in unsuccessful_ordered_files:
            fail_out.write("{}\t{}\n".format(file, unsuccessful[file]))
    
        success_out.close()
        fail_out.close()
        
        #remove pointless .readcount files
        readcount_files = glob.glob("{}/aligned_reads/*.readcount".format(output_dir))
        for f in readcount_files:
            os.remove(f)
        
        if len(unsuccessful_directories) == 2:
            print "No successful Trinity assemblies"
            die_with_empty_cell(cell_name,  output_dir)

    
    
    def run_IgBlast(self, igblast, locus_names, output_dir, cell_name, index_location, ig_seqtype, should_resume):
        print  "##Running IgBLAST##"
        
        if should_resume:
            igblast_out_A = "{output_dir}/IgBLAST_output/{cell_name}_TCRA.IgBLASTOut".format(output_dir=output_dir, cell_name=cell_name)
            igblast_out_B = "{output_dir}/IgBLAST_output/{cell_name}_TCRB.IgBLASTOut".format(output_dir=output_dir, cell_name=cell_name)
            if (os.path.isfile(igblast_out_A) and os.path.getsize(igblast_out_A)>0) or (os.path.isfile(igblast_out_B) and os.path.getsize(igblast_out_B)>0):
                print "Resuming with existing IgBLAST output"
                return
        
        databases = {}
        for segment in ['v','d','j']:
            databases[segment] = "{}/imgt_tcr_db_{}.fa".format(index_location,segment)
        
        #lines below suppress Igblast warning about not having an auxliary file. Taken from http://stackoverflow.com/questions/11269575/how-to-hide-output-of-subprocess-in-python-2-7
        try:
            from subprocess import DEVNULL # py3k
        except ImportError:
            DEVNULL = open(os.devnull, 'wb')
        
             
        for locus in locus_names:
            print "##{}##".format(locus)
            trinity_fasta = "{}/Trinity_output/{}_{}.Trinity.fasta".format(output_dir, cell_name, locus)
            #command = [igblast, '-germline_db_V', databases['v'], '-germline_db_D', databases['d'], '-germline_db_J', databases['j'], '-organism', organism, '-domain_system', 'imgt', '-ig_seqtype', ig_seqtype, '-auxiliary_data', auxdatafile, '-show_translation', '-num_alignments_V', '5', '-num_alignments_D', '5', '-num_alignments_J', '5', '-outfmt', '7', '-query', trinity_fasta]
            command = [igblast, '-germline_db_V', databases['v'], '-germline_db_D', databases['d'], '-germline_db_J', databases['j'], '-domain_system', 'imgt', '-ig_seqtype', ig_seqtype, '-show_translation', '-num_alignments_V', '5', '-num_alignments_D', '5', '-num_alignments_J', '5', '-outfmt', '7', '-query', trinity_fasta]
            igblast_out = "{output_dir}/IgBLAST_output/{cell_name}_{locus}.IgBLASTOut".format(output_dir=output_dir, cell_name=cell_name, locus=locus)
            out = open(igblast_out, 'w')
            subprocess.check_call(command, stdout=out,stderr=DEVNULL)
            out.close()
        
        DEVNULL.close()
        
    
    
    def quantify_with_kallisto(self, kallisto, cell, output_dir, cell_name, kallisto_base_transcriptome, fastq1, fastq2, ncores, should_resume):
        print "##Running Kallisto##"
        if should_resume:
            if os.path.isfile("{}/expression_quantification/kallisto_output/abundance.tsv".format(output_dir)):
                print "Resuming with existing Kallisto output"
                return
        
        print "##Making Kallisto indices##"
        kallisto_dirs = ['kallisto_index', 'kallisto_output']
        for d in kallisto_dirs:
            tracer.makeOutputDir("{}/expression_quantification/{}".format(output_dir, d))
        fasta_filename = "{output_dir}/unfiltered_TCR_seqs/{cell_name}_TCRseqs.fa".format(output_dir=output_dir, cell_name=cell_name)
        fasta_file = open(fasta_filename, 'w')
        fasta_file.write(cell.get_fasta_string())    
        fasta_file.close()
        
        output_transcriptome = "{}/expression_quantification/kallisto_index/{}_transcriptome.fa".format(output_dir, cell_name)
        with open(output_transcriptome, 'w') as outfile:
            for fname in [kallisto_base_transcriptome, fasta_filename]:
                with open(fname) as infile:
                    for line in infile:
                        outfile.write(line)
        
        idx_file = "{}/expression_quantification/kallisto_index/{}_transcriptome.idx".format(output_dir, cell_name)
        
        index_command = [kallisto, 'index', '-i', idx_file, output_transcriptome]
        subprocess.check_call(index_command)
        print "##Quantifying with Kallisto##"
        kallisto_command = [kallisto, 'quant', '-i', idx_file, '-t', ncores, '-o', "{}/expression_quantification/kallisto_output".format(output_dir), fastq1, fastq2]
        subprocess.check_call(kallisto_command)
        
        #delete index file because it's huge and unecessary
        os.remove(idx_file)
        
        
    def print_cell_summary(self, cell, output_file):
        out_file = open(output_file, 'w')
        out_file.write('------------------\n{name}\n------------------\n'.format(name=cell.name))
        out_file.write('TCRA recombinants: {}\n'.format(cell.summarise_productivity('A')))
        out_file.write('TCRB recombinants: {}\n'.format(cell.summarise_productivity('B')))
        out_file.write('\n\n')
        out_file.write('#TCRA#\n')
        if cell.A_recombinants is None:
            out_file.write("No TCRA recombinants found\n\n")
        else:
            for rec in cell.A_recombinants:
                out_file.write(rec.get_summary())
                out_file.write("\n\n")
        out_file.write('#TCRB#\n')
        
        if cell.B_recombinants is None:
            out_file.write("No TCRB recombinants found\n\n")
        else:
            for rec in cell.B_recombinants:
                out_file.write(rec.get_summary())
                out_file.write("\n\n")
        out_file.close()

    def die_with_empty_cell(self, cell_name,  output_dir):
        cell = tracer.Cell(cell_name, None, None, None, None,  is_empty=True)
        self.print_cell_summary(cell, "{output_dir}/unfiltered_TCR_seqs/unfiltered_TCRs.txt".format(output_dir=output_dir))
        pickle.dump(cell, open("{output_dir}/unfiltered_TCR_seqs/{cell_name}.pkl".format(output_dir=output_dir, cell_name=cell.name), 'w'))
        cell.filter_recombinants()
        self.print_cell_summary(cell, "{output_dir}/filtered_TCR_seqs/filtered_TCRs.txt".format(output_dir=output_dir))
        pickle.dump(cell, open("{output_dir}/filtered_TCR_seqs/{cell_name}.pkl".format(output_dir=output_dir, cell_name=cell.name), 'w'))
        exit(1)

##SUMMARISE

    def summarise(self):
        parser = argparse.ArgumentParser(description = "Summarise set of cells with reconstructed TCR sequences")
        parser.add_argument('--config_file', '-c', metavar="<CONFIG_FILE>", help='config file to use [tracer.conf]', default='tracer.conf')
        parser.add_argument('--use_unfiltered', '-u', help='use unfiltered recombinants', action="store_true")
        parser.add_argument('--keep_inkt', '-i', help='ignore iNKT cells when constructing networks', action="store_true")
        parser.add_argument('--graph_format', '-f', metavar="<GRAPH_FORMAT>", help='graphviz output format [pdf]', default='pdf')
        parser.add_argument('dir', metavar="<DIR>", help='directory containing subdirectories for each cell to be summarised')
        args = parser.parse_args(sys.argv[2:])
        
        root_dir = os.path.abspath(args.dir)
        graph_format = args.graph_format

        
        #Read config file
        config = ConfigParser.ConfigParser()
        config.read(args.config_file)
        
        dot = config.get('tool_locations', 'dot_path')
        neato = config.get('tool_locations', 'neato_path')

        #check that executables from config file can be used
        not_executable = []
        for name, x in {"dot":dot, "neato":neato}.iteritems():
            if not tracer.is_exe(x):
                not_executable.append((name, x))
        if len(not_executable) > 0:
            print
            print "Could not execute the following required tools. Check your configuration file."
            for t in not_executable:
                print t[0], t[1]
            print
            exit(1)
        
        cells = {}
        empty_cells = []
        NKT_cells = {}
        subdirectories = os.walk(root_dir).next()[1]
        
        if args.use_unfiltered:
            pkl_dir = "unfiltered_TCR_seqs"
            outdir = "{}/unfiltered_TCR_summary".format(root_dir)
            #outfile = open("{root_dir}/unfiltered_TCR_summary.txt".format(root_dir=root_dir), 'w')
            #length_filename_root = "{}/unfiltered_reconstructed_lengths_TCR".format(root_dir)

        else:
            pkl_dir = "filtered_TCR_seqs"
            outdir = "{}/filtered_TCR_summary".format(root_dir)
            #outfile = open("{root_dir}/filtered_TCR_summary.txt".format(root_dir=root_dir), 'w')
            #length_filename_root = "{}/filtered_reconstructed_lengths_TCR".format(root_dir)
        
        tracer.makeOutputDir(outdir)
        
        
        outfile = open("{}/TCR_summary.txt".format(outdir), 'w')
        length_filename_root = "{}/reconstructed_lengths_TCR".format(outdir)
        
        
        for d in subdirectories:
            cell_pkl = "{root_dir}/{d}/{pkl_dir}/{d}.pkl".format(pkl_dir=pkl_dir, d=d, root_dir=root_dir)
            if os.path.isfile(cell_pkl):
                cl = pickle.load(open(cell_pkl))
                cells[d] = cl
                if cl.is_empty:
                    empty_cells.append(d)
                if cl.is_inkt:
                    NKT_cells[d] = (cl.is_inkt, cl.getMainRecombinantIdentifiersForLocus('B'))
        
        count_of_cells_with_alpha_recovered = 0
        count_of_cells_with_beta_recovered = 0
        count_of_cells_with_paired_recovered = 0
        for cell_name, cell in cells.iteritems():
            prod_a_count = cell.count_productive_recombinants('A')
            prod_b_count = cell.count_productive_recombinants('B')
            if prod_a_count > 0:
                count_of_cells_with_alpha_recovered += 1
            if prod_b_count > 0:
                count_of_cells_with_beta_recovered += 1
            if prod_a_count > 0 and prod_b_count > 0:
                count_of_cells_with_paired_recovered += 1
        
        total_cells = len(cells)
        
        outfile.write("TCRA reconstruction:\t{count_of_cells_with_alpha_recovered} / {total_cells} ({alpha_percent}%)\nTCRB reconstruction:\t{count_of_cells_with_beta_recovered} / {total_cells} ({beta_percent}%)\nPaired productive chains\t{count_of_cells_with_paired_recovered} / {total_cells} ({paired_percent}%)\n\n".format(paired_percent=round((count_of_cells_with_paired_recovered/float(total_cells))*100,1), total_cells=total_cells, alpha_percent=round((count_of_cells_with_alpha_recovered/float(total_cells))*100,1), beta_percent=round((count_of_cells_with_beta_recovered/float(total_cells))*100,1), count_of_cells_with_beta_recovered=count_of_cells_with_beta_recovered, count_of_cells_with_paired_recovered=count_of_cells_with_paired_recovered, count_of_cells_with_alpha_recovered=count_of_cells_with_alpha_recovered))

        
        all_alpha_counter = Counter()
        all_beta_counter = Counter()
        prod_alpha_counter = Counter()
        prod_beta_count = Counter()
        
        counters = {'all_alpha':Counter(), 'all_beta':Counter(), 'prod_alpha':Counter(), 'prod_beta':Counter()}
        
        for cell in cells.values():
            counters['all_alpha'].update({cell.count_total_recombinants('A') : 1})
            counters['all_beta'].update({cell.count_total_recombinants('B') : 1})
            counters['prod_alpha'].update({cell.count_productive_recombinants('A') : 1})
            counters['prod_beta'].update({cell.count_productive_recombinants('B') : 1})
        
        max_recombinant_count = max(counters['all_alpha'].keys() + counters['all_beta'].keys())
        table_header = ['', '0 recombinants', '1 recombinant', '2 recombinants']
        recomb_range = range(0,3)
        if max_recombinant_count > 2:
            extra_header = [str(x) + " recombinants" for x in range(3, max_recombinant_count+1)]
            table_header = table_header + extra_header
            recomb_range = range(0, max_recombinant_count+1)
        
        t = PrettyTable(table_header)
        t.padding_width = 1
        t.align = "l"
        for label in ['all_alpha', 'all_beta', 'prod_alpha', 'prod_beta']:
            counter = counters[label]
            count_array = [counter[x] for x in recomb_range]
            total_with_at_least_one = sum(count_array[1:])
            percentages = ['']+[" ("+ str(round((float(x)/total_with_at_least_one)*100)) +"%)" for x in count_array[1:]]
            row = []
            for i in recomb_range:
                row.append(str(count_array[i]) + percentages[i])
            
            t.add_row([label] + row)
        outfile.write(t.get_string())
     
        
        #Reporting iNKT cells
        iNKT_count = len(NKT_cells)
        if iNKT_count == 1:
            cell_word = 'cell'
        else:
            cell_word = 'cells'
        outfile.write("\n\n#iNKT cells#\nFound {iNKT_count} iNKT {cell_word}\n".format(iNKT_count=iNKT_count, cell_word=cell_word))
        if iNKT_count >0:
            for cell_name, ids in iNKT_cells.iteritems():
                outfile.write("###{cell_name}###\n".format(cell_name=cell_name))
                outfile.write("TCRA:\t{}\nTCRB\t{}\n\n".format(ids[0], ids[1]))

        
        
        #plot lengths of reconstructed sequences
        lengths = {'A':[], 'B':[]}
        for cell in cells.values():
            for locus in lengths.keys():
                lengths[locus] = lengths[locus] +  cell.get_trinity_lengths(locus)
        
        #plot TCRA length distributions
        plt.figure()
        plt.axvline(334, linestyle="--", color = 'k')
        plt.axvline(344, linestyle="--",color = 'k')
        sns.distplot(lengths['A'])
        sns.despine()
        plt.savefig("{}A.pdf".format(length_filename_root)) 
        
        #plot TCRB length distributions
        plt.figure()
        plt.axvline(339, linestyle="--", color = 'k')
        plt.axvline(345, linestyle="--",color = 'k')
        sns.distplot(lengths['B'])
        sns.despine()
        plt.savefig("{}B.pdf".format(length_filename_root))
        
        
        for cell_name in empty_cells:
            del cells[cell_name]
        
        if not args.keep_inkt:
            for cell_name in NKT_cells.keys():
                del cells[cell_name]
                
        #make clonotype networks
        tracer.draw_network_from_cells(cells, outdir, graph_format, dot, neato)         
        
        #plot clonotype sizes
        plt.figure()
        clonotype_sizes = tracer.get_component_groups_sizes(cells)
        w = 0.85
        x_range = range(1, len(clonotype_sizes) + 1)
        plt.bar(x_range, height=clonotype_sizes, width=w, color='black', align='center')
        plt.gca().set_xticks(x_range)
        plt.savefig("{}/clonotype_sizes.pdf".format(outdir))

    summarize = summarise

if __name__ == '__main__':
    Launcher()